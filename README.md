# ğŸ¤– Chatbot Project â€“ Digital Human Architecture

This project is a **fullâ€‘stack AI chatbot system** built with a modular, agentâ€‘based backend and a modern frontend. It is designed to simulate a **Digital Human** that can reason, retrieve memory, use RAG (Retrieval Augmented Generation), and maintain conversational context.

The architecture is intentionally clean and extensible so that individual agents (decision, memory, RAG, etc.) can evolve independently.

---

## ğŸ§  Core Capabilities

### 1. Conversational Intelligence

* Accepts user queries from Web UI
* Maintains conversation context per session
* Produces coherent, stateâ€‘aware responses

### 2. Decisionâ€‘Driven Agent Flow

* A **Decision Agent** determines what actions are required per message:

  * Memory access
  * Chat history lookup
  * RAG (vector search)
  * Direct LLM response

### 3. Memory System (Longâ€‘Term)

* Stores userâ€‘specific memory (preferences, facts, context)
* Backed by **PostgreSQL**
* Accessed only when the Decision Agent deems it necessary


### 4. Chat History Persistence

* Stores full chat history in PostgreSQL
* Allows:

  * Context replay
  * Historyâ€‘aware responses

### 5. RAG (Retrieval Augmented Generation)

* Uses **pgvector** for semantic search
* Retrieves relevant documents when knowledge grounding is required

### 6. Prompt Engineering Pipeline

* Memory Formatter
* History Formatter
* RAG Formatter
* Unified **Prompt Builder**

### 7. Extensible Agent Architecture

* Each responsibility lives in its own module
* Easy to plug in:

  * New agents
  * New tools
  * New memory strategies

---

## ğŸ§© Highâ€‘Level Architecture Flow

1. **User** sends a message from Frontend UI
2. **FastAPI Gateway** receives the request
3. Pipeline steps:

   * Authentication check
   * Input validation
   * Session lookup
   * Redis state read/write
4. Request forwarded to **Decision Agent**
5. Decision Agent decides:

   * Memory needed?
   * Chat history needed?
   * RAG needed?
   * Or direct LLM call?
6. Required data is fetched and formatted
7. Final prompt is built
8. **LLM Model** generates the response
9. Response is returned to the user

---

## ğŸ§  Agents Overview

### ğŸ§­ Decision Agent

**Responsibility:**

* Central brain of the system
* Analyzes user input
* Produces a decision plan

**Decisions include:**

* Save memory or not
* Load chat history or not
* Trigger RAG or not

---

### ğŸ§  Memory Agent

**Responsibility:**

* Persist longâ€‘term user memories
* Fetch relevant memory records

**Storage:**

* PostgreSQL (`memory_store`)

---

### ğŸ’¬ Chat History Agent

**Responsibility:**

* Retrieve past conversation turns
* Maintain conversational continuity

**Storage:**

* PostgreSQL (`chat_messages`)

---

### ğŸ“š RAG Agent

**Responsibility:**

* Perform semantic search
* Fetch relevant documents

**Storage:**

* PostgreSQL + pgvector

---

### ğŸ§± Prompt Builder

**Responsibility:**

* Combine:

  * System prompt
  * Memory context
  * Chat history
  * Retrieved documents
* Produce final LLM prompt

---

## ğŸ›  Tech Stack

### Backend

* Python **3.10 â€“ 3.11 only**
* FastAPI
* SQLAlchemy
* PostgreSQL
* pgvector
* Redis
* Uvicorn

### Frontend

* Next.js / React
* TypeScript
* Modern UI stack

---

## ğŸš€ Running the Project (Local Setup)

> âš ï¸ **Important:** Python 3.10 or 3.11 only. Do NOT use Python 3.12+

---

## ğŸ”§ Backend Setup

### 1ï¸âƒ£ Go to backend directory

```bash
cd backend
```

### 2ï¸âƒ£ Delete existing virtual environment (if present)

```bash
# Windows
rmdir /s /q venv
```

### 3ï¸âƒ£ Create fresh virtual environment

```bash
python -m venv venv
```

### 4ï¸âƒ£ Activate virtual environment

```bash
# Windows
venv\Scripts\activate
```

### 5ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 6ï¸âƒ£ Run backend server

```bash
uvicorn main:app --reload --port 8000
```

Backend will run at:

```
http://127.0.0.1:8000
```

---

## ğŸ¨ Frontend Setup

### 1ï¸âƒ£ Go to frontend directory

```bash
cd frontend
```

### 2ï¸âƒ£ Install dependencies (only first time or when packages change)

```bash
npm install
```

### 3ï¸âƒ£ Start frontend dev server

```bash
npm run dev
```

Frontend will run at:

```
http://localhost:3000
```

---

## ğŸ“ Project Structure (Simplified)

```
chatbot-project-main/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ chat.py
â”‚   â”œâ”€â”€ auth.py
â”‚   â”œâ”€â”€ digital_human/
â”‚   â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”‚   â””â”€â”€ state.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ venv/
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ README.md
```

---

## ğŸ”’ Environment Notes

* Ensure PostgreSQL, Redis, and pgvector are running
* Environment variables should be configured before production use

---

## ğŸ§© Future Extensions

* Multiâ€‘agent collaboration
* Tool calling (APIs, DB actions)
* Longâ€‘term memory summarization
* Streaming responses
* User personalization

---

## âœ… Summary

This project is a **productionâ€‘grade AI chatbot foundation** with:

* Clean agent boundaries
* Decisionâ€‘first architecture
* Memory + RAG integration
* Scalable backend design

Perfect for building **Digital Humans**, AI assistants, or enterprise chat systems ğŸš€
