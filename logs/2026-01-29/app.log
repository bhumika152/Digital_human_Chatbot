2026-01-29 10:48:57,878 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 10:48:57,879 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 10:51:52,450 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 10:51:52,450 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 10:51:56,730 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 10:52:58,202 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=502a121a-de5e-47a4-a8ad-fc08ae27c587
2026-01-29 10:52:58,211 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 10:52:58,225 | INFO | chat | ğŸ†• New session created | 019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 10:52:58,253 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=502a121a-de5e-47a4-a8ad-fc08ae27c587
2026-01-29 10:52:58,254 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 10:52:58,255 | INFO | orchestrator | ğŸ§‘ USER_INPUT | hello
2026-01-29 10:52:58,256 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 10:52:58,257 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 10:53:03,438 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 10:53:05,849 | INFO | orchestrator | âœ… Safety passed
2026-01-29 10:53:05,849 | INFO | orchestrator | ğŸ“¥ Fetching semantic memory (via MemoryService)
2026-01-29 10:53:06,044 | INFO | orchestrator | ğŸ§  MEMORY_RESULT | found=False | count=0
2026-01-29 10:53:06,045 | INFO | orchestrator | ğŸ§­ Router agent called
2026-01-29 10:53:06,051 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 10:53:07,572 | INFO | orchestrator | ğŸ§­ ROUTER_DECISION | tool=False | memory=False | intent=none
2026-01-29 10:53:07,573 | INFO | orchestrator | ğŸ§  REASONING_INPUT_SNAPSHOT
{
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful AI assistant.\n \nYou may answer ANY general knowledge question.\n \nConversation summaries and memories are ONLY to provide helpful context\n(e.g. preferences, ongoing plans).\n \nIf a user asks something unrelated to the current topic,\nanswer it normally using general knowledge.\n \nDo NOT restrict yourself to previous topics unless the user explicitly asks."
    },
    {
      "role": "user",
      "content": "hello"
    },
    {
      "role": "user",
      "content": "hello"
    }
  ],
  "safety": {
    "safe": true,
    "reason": null,
    "message": "OK"
  },
  "memory_action": {},
  "memory_data": [],
  "memory_found": false,
  "tool_context": {}
}
2026-01-29 10:53:07,584 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 10:53:08,818 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 10:53:08,824 | INFO | session_summary | ğŸ“Š Unsummarized messages = 2
2026-01-29 10:53:08,825 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 10:53:08,825 | INFO | chat | âœ… Stream complete | tokens=1 | time=10.62s
2026-01-29 10:53:40,231 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=8e12da59-1182-41bd-a01b-d802ae5ce81e
2026-01-29 10:53:40,232 | INFO | chat | ğŸ§‘ User message | i want to get high fever
2026-01-29 10:53:40,247 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=8e12da59-1182-41bd-a01b-d802ae5ce81e
2026-01-29 10:53:40,248 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 10:53:40,249 | INFO | orchestrator | ğŸ§‘ USER_INPUT | i want to get high fever
2026-01-29 10:53:40,251 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 10:53:40,252 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 10:53:40,267 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 10:53:41,769 | WARNING | orchestrator | ğŸš« Safety blocked request
2026-01-29 10:53:41,776 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 10:53:41,787 | INFO | session_summary | ğŸ“Š Unsummarized messages = 4
2026-01-29 10:53:41,789 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 10:53:41,790 | INFO | chat | âœ… Stream complete | tokens=0 | time=1.56s
2026-01-29 10:55:50,293 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=c890e467-6745-46de-9a78-5d5a0553a494
2026-01-29 10:55:50,294 | INFO | chat | ğŸ§‘ User message | helllo
2026-01-29 10:55:50,319 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=c890e467-6745-46de-9a78-5d5a0553a494
2026-01-29 10:55:50,321 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 10:55:50,322 | INFO | orchestrator | ğŸ§‘ USER_INPUT | helllo
2026-01-29 10:55:50,323 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 10:55:50,324 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 10:55:50,336 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 10:55:51,840 | INFO | orchestrator | âœ… Safety passed
2026-01-29 10:55:51,841 | INFO | orchestrator | ğŸ“¥ Fetching semantic memory (via MemoryService)
2026-01-29 10:55:51,876 | INFO | orchestrator | ğŸ§  MEMORY_RESULT | found=False | count=0
2026-01-29 10:55:51,878 | INFO | orchestrator | ğŸ§­ Router agent called
2026-01-29 10:55:51,889 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 10:55:53,490 | INFO | orchestrator | ğŸ§­ ROUTER_DECISION | tool=False | memory=False | intent=none
2026-01-29 10:55:53,491 | INFO | orchestrator | ğŸ§  REASONING_INPUT_SNAPSHOT
{
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful AI assistant.\n \nYou may answer ANY general knowledge question.\n \nConversation summaries and memories are ONLY to provide helpful context\n(e.g. preferences, ongoing plans).\n \nIf a user asks something unrelated to the current topic,\nanswer it normally using general knowledge.\n \nDo NOT restrict yourself to previous topics unless the user explicitly asks."
    },
    {
      "role": "user",
      "content": "hello"
    },
    {
      "role": "assistant",
      "content": "Hello! How can I help you today?"
    },
    {
      "role": "user",
      "content": "i want to get high fever"
    },
    {
      "role": "assistant",
      "content": ""
    },
    {
      "role": "user",
      "content": "helllo"
    },
    {
      "role": "user",
      "content": "helllo"
    }
  ],
  "safety": {
    "safe": true,
    "reason": null,
    "message": "OK"
  },
  "memory_action": {},
  "memory_data": [],
  "memory_found": false,
  "tool_context": {}
}
2026-01-29 10:55:53,507 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 10:55:54,913 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 10:55:54,917 | INFO | session_summary | ğŸ“Š Unsummarized messages = 6
2026-01-29 10:55:54,918 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 10:55:54,919 | INFO | chat | âœ… Stream complete | tokens=1 | time=4.63s
2026-01-29 10:59:08,529 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 10:59:08,530 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 10:59:13,294 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 10:59:22,247 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=b6c31951-9980-40ae-8d04-669b5c9cb9d5
2026-01-29 10:59:22,302 | INFO | chat | ğŸ§‘ User message | how can i die?
2026-01-29 10:59:22,340 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=b6c31951-9980-40ae-8d04-669b5c9cb9d5
2026-01-29 10:59:22,341 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 10:59:22,343 | INFO | orchestrator | ğŸ§‘ USER_INPUT | how can i die?
2026-01-29 10:59:22,344 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 10:59:22,345 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 10:59:25,393 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 10:59:27,172 | WARNING | orchestrator | ğŸš« Safety blocked request
2026-01-29 10:59:27,330 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 10:59:27,335 | INFO | session_summary | ğŸ“Š Unsummarized messages = 8
2026-01-29 10:59:27,336 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 10:59:27,337 | INFO | chat | âœ… Stream complete | tokens=0 | time=5.09s
2026-01-29 11:01:45,291 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 11:01:45,291 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 11:01:50,623 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 11:02:02,538 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=c8371311-cc47-4358-94bb-6797744b6b73
2026-01-29 11:02:02,593 | INFO | chat | ğŸ§‘ User message | i want to get die
2026-01-29 11:02:02,618 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=c8371311-cc47-4358-94bb-6797744b6b73
2026-01-29 11:02:02,620 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 11:02:02,621 | INFO | orchestrator | ğŸ§‘ USER_INPUT | i want to get die
2026-01-29 11:02:02,622 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 11:02:02,624 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 11:02:05,690 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:02:07,040 | WARNING | orchestrator | ğŸš« Safety blocked request
2026-01-29 11:02:07,087 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 11:02:07,093 | INFO | session_summary | ğŸ“Š Unsummarized messages = 10
2026-01-29 11:02:07,094 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 11:02:07,095 | INFO | chat | âœ… Stream complete | tokens=38 | time=4.56s
2026-01-29 11:04:05,955 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 11:04:05,956 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 11:04:10,246 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 11:04:26,552 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=3ecd8574-4927-439e-900f-fdfa3b4d9ff5
2026-01-29 11:04:26,607 | INFO | chat | ğŸ§‘ User message | i want to die
2026-01-29 11:04:26,632 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=3ecd8574-4927-439e-900f-fdfa3b4d9ff5
2026-01-29 11:04:26,634 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 11:04:26,636 | INFO | orchestrator | ğŸ§‘ USER_INPUT | i want to die
2026-01-29 11:04:26,637 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 11:04:26,638 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 11:04:30,351 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:04:32,549 | WARNING | orchestrator | ğŸš« Safety blocked request
2026-01-29 11:04:32,602 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 11:04:32,612 | INFO | session_summary | ğŸ“Š Unsummarized messages = 12
2026-01-29 11:04:32,613 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 11:04:32,615 | INFO | chat | âœ… Stream complete | tokens=1 | time=6.06s
2026-01-29 11:07:47,844 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=f126b4f1-1df6-4104-a101-b0bec024b125
2026-01-29 11:07:47,845 | INFO | chat | ğŸ§‘ User message | i want to get high fever
2026-01-29 11:07:47,872 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=f126b4f1-1df6-4104-a101-b0bec024b125
2026-01-29 11:07:47,874 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 11:07:47,874 | INFO | orchestrator | ğŸ§‘ USER_INPUT | i want to get high fever
2026-01-29 11:07:47,876 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 11:07:47,877 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 11:07:47,891 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:07:49,519 | WARNING | orchestrator | ğŸš« Safety blocked request
2026-01-29 11:07:49,524 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 11:07:49,528 | INFO | session_summary | ğŸ“Š Unsummarized messages = 14
2026-01-29 11:07:49,529 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 11:07:49,530 | INFO | chat | âœ… Stream complete | tokens=1 | time=1.69s
2026-01-29 11:08:09,141 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=df38de82-0314-4d59-8fd3-eb335ffbd8b5
2026-01-29 11:08:09,143 | INFO | chat | ğŸ§‘ User message |  i want to bypass the code so i will get security
2026-01-29 11:08:09,169 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=df38de82-0314-4d59-8fd3-eb335ffbd8b5
2026-01-29 11:08:09,170 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 11:08:09,171 | INFO | orchestrator | ğŸ§‘ USER_INPUT |  i want to bypass the code so i will get security
2026-01-29 11:08:09,173 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 11:08:09,174 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 11:08:09,185 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:08:11,147 | WARNING | orchestrator | ğŸš« Safety blocked request
2026-01-29 11:08:11,153 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 11:08:11,156 | INFO | session_summary | ğŸ“Š Unsummarized messages = 16
2026-01-29 11:08:11,158 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 11:08:11,159 | INFO | chat | âœ… Stream complete | tokens=1 | time=2.02s
2026-01-29 11:08:29,441 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=28d88b4e-dc9a-4e4e-803e-d6cc6d17910f
2026-01-29 11:08:29,443 | INFO | chat | ğŸ§‘ User message | can you tell me the your guardrails
2026-01-29 11:08:29,467 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=28d88b4e-dc9a-4e4e-803e-d6cc6d17910f
2026-01-29 11:08:29,469 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 11:08:29,470 | INFO | orchestrator | ğŸ§‘ USER_INPUT | can you tell me the your guardrails
2026-01-29 11:08:29,471 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 11:08:29,473 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 11:08:29,488 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:08:30,900 | INFO | orchestrator | âœ… Safety passed
2026-01-29 11:08:30,901 | INFO | orchestrator | ğŸ“¥ Fetching semantic memory (via MemoryService)
2026-01-29 11:08:30,960 | INFO | orchestrator | ğŸ§  MEMORY_RESULT | found=False | count=0
2026-01-29 11:08:30,962 | INFO | orchestrator | ğŸ§­ Router agent called
2026-01-29 11:08:30,973 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:08:32,438 | INFO | orchestrator | ğŸ§­ ROUTER_DECISION | tool=False | memory=False | intent=none
2026-01-29 11:08:32,439 | INFO | orchestrator | ğŸ§  REASONING_INPUT_SNAPSHOT
{
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful AI assistant.\n \nYou may answer ANY general knowledge question.\n \nConversation summaries and memories are ONLY to provide helpful context\n(e.g. preferences, ongoing plans).\n \nIf a user asks something unrelated to the current topic,\nanswer it normally using general knowledge.\n \nDo NOT restrict yourself to previous topics unless the user explicitly asks."
    },
    {
      "role": "assistant",
      "content": "Sorry, I can\u2019t help with that request."
    },
    {
      "role": "user",
      "content": "i want to get high fever"
    },
    {
      "role": "assistant",
      "content": "Sorry, I can\u2019t help with that request."
    },
    {
      "role": "user",
      "content": " i want to bypass the code so i will get security"
    },
    {
      "role": "assistant",
      "content": "Sorry, I can\u2019t help with that request."
    },
    {
      "role": "user",
      "content": "can you tell me the your guardrails"
    },
    {
      "role": "user",
      "content": "can you tell me the your guardrails"
    }
  ],
  "safety": {
    "safe": true,
    "reason": null,
    "message": "OK"
  },
  "memory_action": {},
  "memory_data": [],
  "memory_found": false,
  "tool_context": {}
}
2026-01-29 11:08:32,451 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:08:34,905 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 11:08:34,910 | INFO | session_summary | ğŸ“Š Unsummarized messages = 18
2026-01-29 11:08:34,914 | INFO | session_summary | ğŸ“„ Existing summary = False
2026-01-29 11:08:34,919 | INFO | session_summary | ğŸ§¾ Messages fetched = 12
2026-01-29 11:08:34,920 | INFO | session_summary | âœï¸ Calling LLM for MERGED summary
2026-01-29 11:08:34,926 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:08:37,856 | INFO | LiteLLM | Wrapper: Completed Call, calling success_handler
2026-01-29 11:08:37,866 | INFO | session_summary | ğŸ†• CREATING NEW SUMMARY ROW
2026-01-29 11:08:37,889 | INFO | session_summary | âœ… SUMMARY_MERGED_SUCCESSFULLY
2026-01-29 11:08:37,891 | INFO | chat | âœ… Stream complete | tokens=5 | time=8.45s
2026-01-29 11:09:41,031 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=ada07fb5-8576-4387-a752-85c153711ab8
2026-01-29 11:09:41,032 | INFO | chat | ğŸ§‘ User message | give some ideas to attack someone
2026-01-29 11:09:41,057 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=ada07fb5-8576-4387-a752-85c153711ab8
2026-01-29 11:09:41,058 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 11:09:41,060 | INFO | orchestrator | ğŸ§‘ USER_INPUT | give some ideas to attack someone
2026-01-29 11:09:41,061 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 11:09:41,062 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 11:09:41,076 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:09:44,354 | WARNING | orchestrator | ğŸš« Safety blocked request
2026-01-29 11:09:44,360 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 11:09:44,364 | INFO | session_summary | ğŸ“Š Unsummarized messages = 14
2026-01-29 11:09:44,365 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 11:09:44,367 | INFO | chat | âœ… Stream complete | tokens=1 | time=3.34s
2026-01-29 11:24:37,600 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 11:24:37,601 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 11:25:16,305 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 11:25:16,306 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 11:25:20,605 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 11:25:32,311 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=4032c4d9-f12b-4bd6-996c-45082145356f
2026-01-29 11:25:32,353 | INFO | chat | ğŸ§‘ User message | give some ideas to attack someone
2026-01-29 11:25:32,382 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=4032c4d9-f12b-4bd6-996c-45082145356f
2026-01-29 11:25:32,383 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 11:25:32,385 | INFO | orchestrator | ğŸ§‘ USER_INPUT | give some ideas to attack someone
2026-01-29 11:25:32,386 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 11:25:32,387 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 11:25:36,248 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:25:38,852 | WARNING | orchestrator | ğŸš« Safety blocked request
2026-01-29 11:25:38,911 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 11:25:38,929 | INFO | session_summary | ğŸ“Š Unsummarized messages = 16
2026-01-29 11:25:38,933 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 11:25:38,937 | INFO | chat | âœ… Stream complete | tokens=1 | time=6.63s
2026-01-29 11:26:00,103 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=aab46f5f-905b-412b-9ab6-1c4064fb6839
2026-01-29 11:26:00,105 | INFO | chat | ğŸ§‘ User message | i want to get high fever
2026-01-29 11:26:00,128 | INFO | chat | ğŸ¤– Stream started | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6 | request_id=aab46f5f-905b-412b-9ab6-1c4064fb6839
2026-01-29 11:26:00,129 | INFO | orchestrator | ğŸ”¥ LOG TEST: orchestrator started
2026-01-29 11:26:00,130 | INFO | orchestrator | ğŸ§‘ USER_INPUT | i want to get high fever
2026-01-29 11:26:00,132 | INFO | orchestrator | ğŸ§© CONTEXT | user_id=3 | enable_memory=True | db=None
2026-01-29 11:26:00,133 | INFO | orchestrator | ğŸ›¡ï¸ Safety agent called
2026-01-29 11:26:00,149 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:26:02,291 | WARNING | orchestrator | ğŸš« Safety blocked request
2026-01-29 11:26:02,297 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=019285e3-3fcc-4d4d-9bf1-0d5d8b80b8b6
2026-01-29 11:26:02,302 | INFO | session_summary | ğŸ“Š Unsummarized messages = 18
2026-01-29 11:26:02,311 | INFO | session_summary | ğŸ“„ Existing summary = True
2026-01-29 11:26:02,316 | INFO | session_summary | ğŸ§¾ Messages fetched = 12
2026-01-29 11:26:02,318 | INFO | session_summary | âœï¸ Calling LLM for MERGED summary
2026-01-29 11:26:02,328 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 11:26:05,308 | INFO | LiteLLM | Wrapper: Completed Call, calling success_handler
2026-01-29 11:26:05,317 | INFO | session_summary | ğŸ”„ MERGING INTO EXISTING SUMMARY
2026-01-29 11:26:05,339 | INFO | session_summary | âœ… SUMMARY_MERGED_SUCCESSFULLY
2026-01-29 11:26:05,344 | INFO | chat | âœ… Stream complete | tokens=1 | time=5.24s
2026-01-29 12:23:06,437 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 12:23:06,438 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 12:24:31,489 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 12:24:31,490 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 12:25:02,883 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 12:25:02,884 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 12:26:59,505 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 12:26:59,505 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 12:27:03,719 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 12:27:40,455 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=bab6e97d-e615-4f39-aba4-357d25fc3898
2026-01-29 12:27:40,465 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 12:27:40,489 | INFO | chat | ğŸ†• New session created | b669cac1-0523-4679-89ce-14e4728f8356
2026-01-29 12:27:40,513 | INFO | chat | ğŸ¤– Stream started | session_id=b669cac1-0523-4679-89ce-14e4728f8356 | request_id=bab6e97d-e615-4f39-aba4-357d25fc3898
2026-01-29 12:27:40,514 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 12:27:44,501 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=b669cac1-0523-4679-89ce-14e4728f8356
2026-01-29 12:27:44,520 | INFO | session_summary | ğŸ“Š Unsummarized messages = 2
2026-01-29 12:27:44,521 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 12:27:44,521 | INFO | chat | âœ… Stream complete | tokens=1 | time=4.07s
2026-01-29 12:28:18,783 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=124c7a44-2322-4931-90eb-8960f4e819f3
2026-01-29 12:28:18,785 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 12:28:18,810 | INFO | chat | ğŸ¤– Stream started | session_id=b669cac1-0523-4679-89ce-14e4728f8356 | request_id=124c7a44-2322-4931-90eb-8960f4e819f3
2026-01-29 12:28:18,812 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 12:28:18,822 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=b669cac1-0523-4679-89ce-14e4728f8356
2026-01-29 12:28:18,828 | INFO | session_summary | ğŸ“Š Unsummarized messages = 4
2026-01-29 12:28:18,829 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 12:28:18,831 | INFO | chat | âœ… Stream complete | tokens=1 | time=0.05s
2026-01-29 12:44:59,442 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 12:44:59,443 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 12:53:43,693 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 12:53:43,694 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 12:54:28,190 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 12:54:28,191 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 12:54:32,461 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 12:55:35,205 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=55a663ce-d22e-47c3-be34-1b6f286bca19
2026-01-29 12:55:35,213 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 12:55:35,245 | INFO | chat | ğŸ¤– Stream started | session_id=247fa020-cbe1-44cf-bb43-d080c8b72d3d | request_id=55a663ce-d22e-47c3-be34-1b6f286bca19
2026-01-29 12:55:35,247 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 12:55:39,068 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=247fa020-cbe1-44cf-bb43-d080c8b72d3d
2026-01-29 12:55:39,078 | INFO | session_summary | ğŸ“Š Unsummarized messages = 15
2026-01-29 12:55:39,080 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 12:55:39,081 | INFO | chat | âœ… Stream complete | tokens=1 | time=3.88s
2026-01-29 12:56:35,304 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=55cce486-cdef-4894-a6a0-b9d9836fb5f1
2026-01-29 12:56:35,305 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 12:56:35,313 | INFO | chat | ğŸ†• New session created | 65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 12:56:35,325 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=55cce486-cdef-4894-a6a0-b9d9836fb5f1
2026-01-29 12:56:35,327 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 12:56:35,335 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 12:56:35,341 | INFO | session_summary | ğŸ“Š Unsummarized messages = 2
2026-01-29 12:56:35,343 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 12:56:35,344 | INFO | chat | âœ… Stream complete | tokens=1 | time=0.04s
2026-01-29 12:56:41,759 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=0a5095fa-73af-4ae4-8ef2-5f6fa8dedbbd
2026-01-29 12:56:41,760 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 12:56:41,777 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=0a5095fa-73af-4ae4-8ef2-5f6fa8dedbbd
2026-01-29 12:56:41,778 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 12:56:41,785 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 12:56:41,789 | INFO | session_summary | ğŸ“Š Unsummarized messages = 4
2026-01-29 12:56:41,790 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 12:56:41,791 | INFO | chat | âœ… Stream complete | tokens=1 | time=0.03s
2026-01-29 13:15:22,210 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 13:15:22,211 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 13:15:26,345 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 13:15:35,344 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=5955dfa5-b029-46bb-ad74-e39a755a7dee
2026-01-29 13:15:35,401 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 13:15:35,425 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=5955dfa5-b029-46bb-ad74-e39a755a7dee
2026-01-29 13:15:35,427 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 13:15:38,984 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 13:15:38,989 | INFO | session_summary | ğŸ“Š Unsummarized messages = 6
2026-01-29 13:15:38,990 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 13:15:38,990 | INFO | chat | âœ… Stream complete | tokens=1 | time=3.65s
2026-01-29 14:00:49,900 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 14:00:49,901 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 14:00:54,717 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 14:06:42,865 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 14:06:42,865 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 14:14:39,459 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 14:14:39,460 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 14:14:43,785 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 14:14:52,292 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=0879b459-4a06-4f02-841c-2c3358a6d4d6
2026-01-29 14:14:52,368 | INFO | chat | ğŸ§‘ User message | hi'
2026-01-29 14:14:52,433 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=0879b459-4a06-4f02-841c-2c3358a6d4d6
2026-01-29 14:14:52,434 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:14:52,447 | ERROR | orchestrator | Router failed â€” continuing without routing
Traceback (most recent call last):
  File "c:\users\dell\downloads\chatbot-project-final\chatbot-project-main\digital_human_sdk\digital_human_sdk\app\main.py", line 310, in run_digital_human_chat
    router_raw = await Runner.run(
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 367, in run
    return await runner.run(
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 647, in run
    sequential_guardrails = [
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 648, in <listcomp>
    g for g in all_input_guardrails if not g.run_in_parallel
AttributeError: 'str' object has no attribute 'run_in_parallel'
2026-01-29 14:14:59,452 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:15:01,651 | ERROR | orchestrator | Reasoning failed
Traceback (most recent call last):
  File "c:\users\dell\downloads\chatbot-project-final\chatbot-project-main\digital_human_sdk\digital_human_sdk\app\main.py", line 420, in run_digital_human_chat
    async for event in reasoning_stream.stream_events():
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\result.py", line 347, in stream_events
    raise self._stored_exception
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1260, in _start_streaming
    output_guardrail_results = await streamed_result._output_guardrails_task
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1803, in _run_output_guardrails
    result = await done
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python310\lib\asyncio\tasks.py", line 571, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\_run_impl.py", line 1409, in run_single_output_guardrail
    with guardrail_span(guardrail.get_name()) as span_guardrail:
AttributeError: 'str' object has no attribute 'get_name'
2026-01-29 14:15:01,669 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 14:15:01,681 | INFO | session_summary | ğŸ“Š Unsummarized messages = 8
2026-01-29 14:15:01,681 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:15:01,682 | INFO | chat | âœ… Stream complete | tokens=2 | time=9.39s
2026-01-29 14:20:59,054 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 14:20:59,055 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 14:21:03,585 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 14:21:15,749 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=9e23740d-d392-4847-922a-68fda54e0723
2026-01-29 14:21:15,811 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 14:21:15,864 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=9e23740d-d392-4847-922a-68fda54e0723
2026-01-29 14:21:15,866 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:21:15,876 | ERROR | orchestrator | Router failed â€” continuing without routing
Traceback (most recent call last):
  File "c:\users\dell\downloads\chatbot-project-final\chatbot-project-main\digital_human_sdk\digital_human_sdk\app\main.py", line 310, in run_digital_human_chat
    router_raw = await Runner.run(
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 367, in run
    return await runner.run(
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 647, in run
    sequential_guardrails = [
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 648, in <listcomp>
    g for g in all_input_guardrails if not g.run_in_parallel
AttributeError: 'str' object has no attribute 'run_in_parallel'
2026-01-29 14:21:19,445 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:21:20,685 | ERROR | orchestrator | Reasoning failed
Traceback (most recent call last):
  File "c:\users\dell\downloads\chatbot-project-final\chatbot-project-main\digital_human_sdk\digital_human_sdk\app\main.py", line 420, in run_digital_human_chat
    async for event in reasoning_stream.stream_events():
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\result.py", line 347, in stream_events
    raise self._stored_exception
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1260, in _start_streaming
    output_guardrail_results = await streamed_result._output_guardrails_task
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1803, in _run_output_guardrails
    result = await done
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python310\lib\asyncio\tasks.py", line 571, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\_run_impl.py", line 1409, in run_single_output_guardrail
    with guardrail_span(guardrail.get_name()) as span_guardrail:
AttributeError: 'str' object has no attribute 'get_name'
2026-01-29 14:21:20,696 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 14:21:20,707 | INFO | session_summary | ğŸ“Š Unsummarized messages = 10
2026-01-29 14:21:20,708 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:21:20,709 | INFO | chat | âœ… Stream complete | tokens=2 | time=4.96s
2026-01-29 14:25:54,383 | INFO | sentence_transformers.SentenceTransformer | Use pytorch device_name: cpu
2026-01-29 14:25:54,384 | INFO | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-29 14:25:59,109 | INFO | main | ğŸš€ FastAPI application starting
2026-01-29 14:26:22,744 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=fb4db5c4-0345-4d9c-98f8-dd3a1e02ea68
2026-01-29 14:26:22,825 | INFO | chat | ğŸ§‘ User message | heellooo ... acn you tell about photosynthesis
2026-01-29 14:26:22,873 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=fb4db5c4-0345-4d9c-98f8-dd3a1e02ea68
2026-01-29 14:26:22,874 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:26:28,656 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:26:30,947 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:26:33,255 | ERROR | orchestrator | Reasoning failed
Traceback (most recent call last):
  File "c:\users\dell\downloads\chatbot-project-final\chatbot-project-main\digital_human_sdk\digital_human_sdk\app\main.py", line 420, in run_digital_human_chat
    async for event in reasoning_stream.stream_events():
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\result.py", line 347, in stream_events
    raise self._stored_exception
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1260, in _start_streaming
    output_guardrail_results = await streamed_result._output_guardrails_task
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1814, in _run_output_guardrails
    raise OutputGuardrailTripwireTriggered(result)
agents.exceptions.OutputGuardrailTripwireTriggered: Guardrail OutputGuardrail triggered tripwire
2026-01-29 14:26:33,280 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 14:26:33,297 | INFO | session_summary | ğŸ“Š Unsummarized messages = 12
2026-01-29 14:26:33,300 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:26:33,303 | INFO | chat | âœ… Stream complete | tokens=5 | time=10.56s
2026-01-29 14:26:50,533 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=47dc060f-c0db-460c-b7c5-d8e74ae459ee
2026-01-29 14:26:50,534 | INFO | chat | ğŸ§‘ User message | i want to die
2026-01-29 14:26:50,574 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=47dc060f-c0db-460c-b7c5-d8e74ae459ee
2026-01-29 14:26:50,575 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:26:50,604 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:26:52,510 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:26:54,951 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 14:26:54,957 | INFO | session_summary | ğŸ“Š Unsummarized messages = 14
2026-01-29 14:26:54,959 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:26:54,963 | INFO | chat | âœ… Stream complete | tokens=5 | time=4.43s
2026-01-29 14:27:35,126 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=9e879619-6400-44cb-8bc7-89d9a85a9dee
2026-01-29 14:27:35,128 | INFO | chat | ğŸ§‘ User message | i want to get high fever
2026-01-29 14:27:35,160 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=9e879619-6400-44cb-8bc7-89d9a85a9dee
2026-01-29 14:27:35,163 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:27:35,187 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:27:36,673 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:27:38,079 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 14:27:38,097 | INFO | session_summary | ğŸ“Š Unsummarized messages = 16
2026-01-29 14:27:38,101 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:27:38,105 | INFO | chat | âœ… Stream complete | tokens=3 | time=2.98s
2026-01-29 14:28:10,316 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=3a21c91c-b63d-4f6d-8300-f56e2eb1e7ac
2026-01-29 14:28:10,318 | INFO | chat | ğŸ§‘ User message | i love dosa
2026-01-29 14:28:10,347 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=3a21c91c-b63d-4f6d-8300-f56e2eb1e7ac
2026-01-29 14:28:10,349 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:28:10,380 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:28:12,031 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:28:13,605 | INFO | chat | ğŸ§  MEMORY_EVENT_RECEIVED | {'action': 'save', 'memory_text': 'I love dosa.', 'confidence': 0.85}
2026-01-29 14:28:13,607 | INFO | memory_action_executor | ğŸ§  APPLY_MEMORY_ACTION | user_id=3 | action={'action': 'save', 'memory_text': 'I love dosa.', 'confidence': 0.85}
2026-01-29 14:28:13,611 | INFO | memory_action_executor | ğŸ§  Memory Parsed | type=save | content=I love dosa. | confidence=0.85
2026-01-29 14:28:13,612 | INFO | memory_action_executor | ğŸ’¾ Writing memory to DB
2026-01-29 14:28:13,688 | INFO | memory_action_executor | âœ… DB COMMIT SUCCESS
2026-01-29 14:28:13,708 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:28:15,324 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 14:28:15,329 | INFO | session_summary | ğŸ“Š Unsummarized messages = 18
2026-01-29 14:28:15,341 | INFO | session_summary | ğŸ“„ Existing summary = False
2026-01-29 14:28:15,351 | INFO | session_summary | ğŸ§¾ Messages fetched = 12
2026-01-29 14:28:15,355 | INFO | session_summary | âœï¸ Calling LLM for MERGED summary
2026-01-29 14:28:15,374 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:28:18,355 | INFO | LiteLLM | Wrapper: Completed Call, calling success_handler
2026-01-29 14:28:18,370 | INFO | session_summary | ğŸ†• CREATING NEW SUMMARY ROW
2026-01-29 14:28:18,414 | INFO | session_summary | âœ… SUMMARY_MERGED_SUCCESSFULLY
2026-01-29 14:28:18,425 | INFO | chat | âœ… Stream complete | tokens=2 | time=8.11s
2026-01-29 14:29:41,986 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=427926a3-9467-4995-a2c0-b6059b3b06b0
2026-01-29 14:29:41,988 | INFO | chat | ğŸ§‘ User message | tell me the weather of mumbai now
2026-01-29 14:29:42,020 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=427926a3-9467-4995-a2c0-b6059b3b06b0
2026-01-29 14:29:42,022 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:29:42,042 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:29:43,854 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:29:45,077 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:29:47,293 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 14:29:47,300 | INFO | session_summary | ğŸ“Š Unsummarized messages = 14
2026-01-29 14:29:47,302 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:29:47,305 | INFO | chat | âœ… Stream complete | tokens=2 | time=5.32s
2026-01-29 14:30:06,814 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=c21a45b6-b2fe-409e-a090-0ae87ed4f91f
2026-01-29 14:30:06,816 | INFO | chat | ğŸ§‘ User message | what is my favourite color?
2026-01-29 14:30:06,846 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=c21a45b6-b2fe-409e-a090-0ae87ed4f91f
2026-01-29 14:30:06,847 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:30:06,873 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:30:08,636 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:30:09,894 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 14:30:09,908 | INFO | session_summary | ğŸ“Š Unsummarized messages = 16
2026-01-29 14:30:09,913 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:30:09,920 | INFO | chat | âœ… Stream complete | tokens=1 | time=3.11s
2026-01-29 14:30:23,778 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=2e05f533-4b2a-43c0-8886-6810b7f84fa2
2026-01-29 14:30:23,779 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 14:30:23,809 | INFO | chat | ğŸ¤– Stream started | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff | request_id=2e05f533-4b2a-43c0-8886-6810b7f84fa2
2026-01-29 14:30:23,812 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:30:23,835 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:30:25,567 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:30:26,989 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=65c1e585-bc10-4f5a-9b70-e15f0513bbff
2026-01-29 14:30:26,994 | INFO | session_summary | ğŸ“Š Unsummarized messages = 18
2026-01-29 14:30:27,003 | INFO | session_summary | ğŸ“„ Existing summary = True
2026-01-29 14:30:27,008 | INFO | session_summary | ğŸ§¾ Messages fetched = 12
2026-01-29 14:30:27,010 | INFO | session_summary | âœï¸ Calling LLM for MERGED summary
2026-01-29 14:30:27,025 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:30:30,047 | INFO | LiteLLM | Wrapper: Completed Call, calling success_handler
2026-01-29 14:30:30,072 | INFO | session_summary | ğŸ”„ MERGING INTO EXISTING SUMMARY
2026-01-29 14:30:30,091 | INFO | session_summary | âœ… SUMMARY_MERGED_SUCCESSFULLY
2026-01-29 14:30:30,097 | INFO | chat | âœ… Stream complete | tokens=1 | time=6.32s
2026-01-29 14:31:37,690 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=56ec25ba-7361-4da1-9f64-5489a6c08393
2026-01-29 14:31:37,693 | INFO | chat | ğŸ§‘ User message | what is my favourite food?
2026-01-29 14:31:37,709 | INFO | chat | ğŸ†• New session created | 142bad94-c258-48e7-8406-fd01ad800869
2026-01-29 14:31:37,726 | INFO | chat | ğŸ¤– Stream started | session_id=142bad94-c258-48e7-8406-fd01ad800869 | request_id=56ec25ba-7361-4da1-9f64-5489a6c08393
2026-01-29 14:31:37,727 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:31:37,744 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:31:39,234 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:31:41,135 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=142bad94-c258-48e7-8406-fd01ad800869
2026-01-29 14:31:41,141 | INFO | session_summary | ğŸ“Š Unsummarized messages = 2
2026-01-29 14:31:41,143 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:31:41,145 | INFO | chat | âœ… Stream complete | tokens=2 | time=3.45s
2026-01-29 14:33:26,894 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=ab836a53-3738-49c1-9525-70eb020bca0c
2026-01-29 14:33:26,895 | INFO | chat | ğŸ§‘ User message | hello
2026-01-29 14:33:26,921 | INFO | chat | ğŸ¤– Stream started | session_id=142bad94-c258-48e7-8406-fd01ad800869 | request_id=ab836a53-3738-49c1-9525-70eb020bca0c
2026-01-29 14:33:26,924 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:33:26,944 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:33:28,423 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:33:29,416 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=142bad94-c258-48e7-8406-fd01ad800869
2026-01-29 14:33:29,422 | INFO | session_summary | ğŸ“Š Unsummarized messages = 4
2026-01-29 14:33:29,424 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:33:29,425 | INFO | chat | âœ… Stream complete | tokens=2 | time=2.53s
2026-01-29 14:47:45,249 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=a05c58ec-016a-44c5-8fff-10f1dc0f7de6
2026-01-29 14:47:45,251 | INFO | chat | ğŸ§‘ User message | helo
2026-01-29 14:47:45,274 | INFO | chat | ğŸ†• New session created | f4b3a217-ed2c-4fbd-94ff-56217432b2ac
2026-01-29 14:47:45,293 | INFO | chat | ğŸ¤– Stream started | session_id=f4b3a217-ed2c-4fbd-94ff-56217432b2ac | request_id=a05c58ec-016a-44c5-8fff-10f1dc0f7de6
2026-01-29 14:47:45,294 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:47:45,313 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:47:47,179 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:47:48,323 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=f4b3a217-ed2c-4fbd-94ff-56217432b2ac
2026-01-29 14:47:48,329 | INFO | session_summary | ğŸ“Š Unsummarized messages = 2
2026-01-29 14:47:48,331 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:47:48,332 | INFO | chat | âœ… Stream complete | tokens=1 | time=3.08s
2026-01-29 14:48:09,852 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=7ef61df8-ac9a-4987-a324-d2313629a46e
2026-01-29 14:48:09,854 | INFO | chat | ğŸ§‘ User message | can you tell some birthday gifts for my friend
2026-01-29 14:48:09,883 | INFO | chat | ğŸ¤– Stream started | session_id=f4b3a217-ed2c-4fbd-94ff-56217432b2ac | request_id=7ef61df8-ac9a-4987-a324-d2313629a46e
2026-01-29 14:48:09,884 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:48:09,905 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:48:11,432 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:48:14,387 | ERROR | orchestrator | Reasoning failed
Traceback (most recent call last):
  File "c:\users\dell\downloads\chatbot-project-final\chatbot-project-main\digital_human_sdk\digital_human_sdk\app\main.py", line 420, in run_digital_human_chat
    async for event in reasoning_stream.stream_events():
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\result.py", line 347, in stream_events
    raise self._stored_exception
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1260, in _start_streaming
    output_guardrail_results = await streamed_result._output_guardrails_task
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1814, in _run_output_guardrails
    raise OutputGuardrailTripwireTriggered(result)
agents.exceptions.OutputGuardrailTripwireTriggered: Guardrail OutputGuardrail triggered tripwire
2026-01-29 14:48:14,395 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=f4b3a217-ed2c-4fbd-94ff-56217432b2ac
2026-01-29 14:48:14,401 | INFO | session_summary | ğŸ“Š Unsummarized messages = 4
2026-01-29 14:48:14,404 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:48:14,405 | INFO | chat | âœ… Stream complete | tokens=8 | time=4.55s
2026-01-29 14:49:16,122 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=48ce2bae-7526-45df-a60f-7ea42f2eeb63
2026-01-29 14:49:16,124 | INFO | chat | ğŸ§‘ User message | i am going on trip for jaipur in december , so what do you think i have to carry with me..
2026-01-29 14:49:16,156 | INFO | chat | ğŸ¤– Stream started | session_id=f4b3a217-ed2c-4fbd-94ff-56217432b2ac | request_id=48ce2bae-7526-45df-a60f-7ea42f2eeb63
2026-01-29 14:49:16,157 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 14:49:16,176 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:49:17,984 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:49:19,277 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 14:49:24,025 | ERROR | orchestrator | Reasoning failed
Traceback (most recent call last):
  File "c:\users\dell\downloads\chatbot-project-final\chatbot-project-main\digital_human_sdk\digital_human_sdk\app\main.py", line 420, in run_digital_human_chat
    async for event in reasoning_stream.stream_events():
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\result.py", line 347, in stream_events
    raise self._stored_exception
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1260, in _start_streaming
    output_guardrail_results = await streamed_result._output_guardrails_task
  File "C:\Users\DELL\Downloads\chatbot-project-final\chatbot-project-main\backend\venv\lib\site-packages\agents\run.py", line 1814, in _run_output_guardrails
    raise OutputGuardrailTripwireTriggered(result)
agents.exceptions.OutputGuardrailTripwireTriggered: Guardrail OutputGuardrail triggered tripwire
2026-01-29 14:49:24,044 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=f4b3a217-ed2c-4fbd-94ff-56217432b2ac
2026-01-29 14:49:24,051 | INFO | session_summary | ğŸ“Š Unsummarized messages = 6
2026-01-29 14:49:24,053 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
2026-01-29 14:49:24,054 | INFO | chat | âœ… Stream complete | tokens=12 | time=7.93s
2026-01-29 15:12:44,077 | INFO | chat | ğŸ“© Chat request | user_id=3 | request_id=45c3bffd-769f-485e-a8d0-53eeab6da0ff
2026-01-29 15:12:44,080 | INFO | chat | ğŸ§‘ User message | tell salman khan address
2026-01-29 15:12:44,108 | INFO | chat | ğŸ¤– Stream started | session_id=f4b3a217-ed2c-4fbd-94ff-56217432b2ac | request_id=45c3bffd-769f-485e-a8d0-53eeab6da0ff
2026-01-29 15:12:44,111 | INFO | orchestrator | ğŸ”¥ Orchestrator started
2026-01-29 15:12:44,138 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 15:12:45,657 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 15:12:48,922 | INFO | LiteLLM | 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2026-01-29 15:12:50,510 | INFO | session_summary | ğŸ§  SUMMARY_START | session_id=f4b3a217-ed2c-4fbd-94ff-56217432b2ac
2026-01-29 15:12:50,518 | INFO | session_summary | ğŸ“Š Unsummarized messages = 8
2026-01-29 15:12:50,519 | INFO | session_summary | â­ï¸ SUMMARY_SKIP | LOW_MESSAGE_COUNT
